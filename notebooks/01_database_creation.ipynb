{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hop Teaming Analysis - Database Preparation\n",
    "\n",
    "## Team: The Hindenburgs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![The Hindenburgs](../img/the_hindenburgs_propaganda.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import sqlite3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hop Teaming Dataset\n",
    "\n",
    "Provided to us by our instructor Michael. More information about the Hop Teaming data can be found at https://careset.com/docgraph-hop-teaming-dataset/. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hop Teaming dataset has columns - from_npi, to_npi, patient_count, transaction_count, average_day_wait, std_day_wait, weill keep all.\n",
    "\n",
    "To test it individually, the code below was used:\n",
    "\n",
    "```\n",
    " chunks = pd.read_csv('../data/DocGraph_Hop_Teaming_2018.csv', chunksize = 10000)\n",
    " test_chunk = next(chunks)\n",
    " test_chunk.loc[(test_chunk['transaction_count'] >= 50) & (test_chunk['average_day_wait'] < 50)]\n",
    "```\n",
    "\n",
    "> NOTE: when going through the entire dataset to store it in the sqlite database, it takes several minutes to complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ad5d4bd3da24a80b5856c12628ee5f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "db = sqlite3.connect('../data/hop_teaming_database.sqlite')\n",
    "\n",
    "for chunk in tqdm(pd.read_csv('../data/DocGraph_Hop_Teaming_2018.csv', chunksize = 10000)):\n",
    "    # filter the required conditions (trying to eliminate accidental referrals)\n",
    "    chunk = chunk.loc[(chunk['transaction_count'] >= 50) & (chunk['average_day_wait'] < 50)] \n",
    "    # Append the chunk to a calls table\n",
    "    chunk.to_sql('hop_teaming', db, if_exists = 'append', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x7f8fca7aa0a0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.execute('CREATE INDEX from_to_npi ON hop_teaming(from_npi, to_npi)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hop teaming dataset is pretty straightforward, only 6 columns. Need to apply some filters which I'll get to later."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NNPES dataset\n",
    "\n",
    "To supplement the Hop Teaming, download the NPPES Data Dissemination from [here](https://download.cms.gov/nppes/NPI_Files.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# below code allows to see all columns, this dataset has 330;\n",
    "# if you want to display less, replace None with columns to display, e.g. 10\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as above, for testing\n",
    "\n",
    "```\n",
    "chunks = pd.read_csv('../data/npidata_pfile_20050523-20230212.csv', chunksize = 10000)\n",
    "test_chunk = next(chunks)\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some providers that have for taxonomy switch 'X' on all taxonomies instead of Y or N.\n",
    "\n",
    "` test_chunk.loc[(test_chunk['Healthcare Provider Primary Taxonomy Switch_1'] != 'Y') & (test_chunk['Healthcare Provider Primary Taxonomy Switch_1'] != 'N')] `\n",
    "\n",
    "In order to access the taxonomies, I first found out how to loop over the columns:\n",
    "\n",
    "```\n",
    "for i in range(1,16):\n",
    "    print(test_chunk.loc[test_chunk[f'Healthcare Provider Primary Taxonomy Switch_{i}'] == 'Y', f'Healthcare Provider Taxonomy Code_{i}'].count())\n",
    "```\n",
    "\n",
    "And then defined the lambda function to apply:\n",
    "\n",
    "```\n",
    "def find_taxonomy(col):  \n",
    "    if col['Healthcare Provider Primary Taxonomy Switch_1'] == 'Y':\n",
    "        return col['Healthcare Provider Taxonomy Code_1']\n",
    "    elif col['Healthcare Provider Primary Taxonomy Switch_2'] == 'Y':\n",
    "    ...\n",
    "    similar code repeated for 15 times\n",
    "    ...\n",
    "    elif col['Healthcare Provider Primary Taxonomy Switch_15'] == 'Y':\n",
    "        return col['Healthcare Provider Taxonomy Code_15']      \n",
    "    return 'no primary taxonomy'\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the compacted version:\n",
    "\n",
    "> NOTE: to store in the database, this part takes even longer than the one above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_taxonomy(col):\n",
    "    for i in range(1, 16):\n",
    "        taxonomy_switch = f'Healthcare Provider Primary Taxonomy Switch_{i}'\n",
    "        taxonomy_value = f'Healthcare Provider Taxonomy Code_{i}'\n",
    "        if col.get(taxonomy_switch) == 'Y':\n",
    "            return col.get(taxonomy_value)\n",
    "    return 'no primary taxonomy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture [--no-stderr]\n",
    "# the capture above is here so that it doesn't show warnings about columns types and so that I avoid manually setting dozens of columns dtypes!\n",
    "\n",
    "db = sqlite3.connect('../data/hop_teaming_database.sqlite')\n",
    "\n",
    "for chunk in tqdm(pd.read_csv('../data/npidata_pfile_20050523-20230212.csv', chunksize = 10000, dtype={'Provider Business Practice Location Address Postal Code': object})):\n",
    "\n",
    "    # first extract the primary taxonomy\n",
    "    chunk['Primary Taxonomy'] = chunk.apply(lambda col: find_taxonomy(col), axis=1)\n",
    "\n",
    "    # take only the first 5 ZIP digits\n",
    "    chunk['Provider Business Practice Location Address Postal Code'] = chunk['Provider Business Practice Location Address Postal Code'].str[:5]\n",
    "\n",
    "    # next, only keep columns we're interested in and renaming so that there are no ()\n",
    "    chunk = (\n",
    "        chunk \n",
    "        [['NPI',\n",
    "        'Entity Type Code',\n",
    "        'Provider Organization Name (Legal Business Name)',\n",
    "        'Provider Last Name (Legal Name)',\n",
    "        'Provider First Name',\n",
    "        'Provider Middle Name',\n",
    "        'Provider Name Prefix Text',\n",
    "        'Provider Name Suffix Text',\n",
    "        'Provider Credential Text',\n",
    "        'Provider First Line Business Practice Location Address',\n",
    "        'Provider Second Line Business Practice Location Address',\n",
    "        'Provider Business Practice Location Address City Name',\n",
    "        'Provider Business Practice Location Address State Name',\n",
    "        'Provider Business Practice Location Address Postal Code',\n",
    "        'Primary Taxonomy']]\n",
    "        .rename(columns={\n",
    "            'Provider Organization Name (Legal Business Name)': 'Organization Name',\n",
    "            'Provider Last Name (Legal Name)': 'Last Name'            \n",
    "            })\n",
    "    )\n",
    "\n",
    "    # Then clean up the column names\n",
    "    chunk.columns = [x.replace('Provider ', '').replace('Business Practice Location ', '').lower().replace(' ', '_') for x in chunk.columns]\n",
    "\n",
    "    # Finally, the chunk to a calls table\n",
    "    chunk.to_sql('nnpes', db, if_exists = 'append', index = False)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x7f8f98225c70>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.execute('CREATE INDEX npi ON nnpes(npi)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## National Uniform Claim Committee\n",
    "\n",
    "Classification for taxonomy codes from [National Uniform Claim Committee](https://www.nucc.org/index.php/code-sets-mainmenu-41/provider-taxonomy-mainmenu-40/csv-mainmenu-57)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 873 rows, 8 columns -- nucc_taxonomy.shape\n",
    "# 238 have 'Definition to come' ... when though?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = sqlite3.connect('../data/hop_teaming_database.sqlite')\n",
    "\n",
    "nucc_taxonomy = pd.read_csv('../data/nucc_taxonomy_230.csv', encoding = 'unicode_escape')\n",
    "\n",
    "# lowercase column names and replace spaces\n",
    "nucc_taxonomy.columns = [x.lower().replace(' ', '_') for x in nucc_taxonomy.columns]\n",
    "\n",
    "# add table to database\n",
    "nucc_taxonomy.to_sql('nucc_taxonomy', db, if_exists = 'append', index = False)\n",
    "\n",
    "#create index\n",
    "db.execute('CREATE INDEX code ON nucc_taxonomy(code)')\n",
    "\n",
    "db.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ZIP code to CBSA\n",
    "\n",
    "From the [CBSA crosswalk](https://www.huduser.gov/portal/datasets/usps_crosswalk.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = sqlite3.connect('../data/hop_teaming_database.sqlite')\n",
    "\n",
    "zip_cbsa = pd.read_excel('../data/ZIP_CBSA_122021.xlsx', index_col = None, header = 0, dtype={'zip': object})\n",
    "\n",
    "# add table to database\n",
    "zip_cbsa.to_sql('zip_cbsa', db, if_exists = 'append', index = False)\n",
    "\n",
    "#create index\n",
    "db.execute('CREATE INDEX zip ON zip_cbsa(zip)')\n",
    "\n",
    "db.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying Providers Affiliation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two datasets that include hospital information and facility affiliation for more in depth analysis.\n",
    "\n",
    "Data obtained from cms:\n",
    "- [Hospital Information](https://data.cms.gov/provider-data/dataset/xubh-q36u)\n",
    "- [Facility Affiliation](https://data.cms.gov/provider-data/dataset/27ea-46a8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = sqlite3.connect('../data/hop_teaming_database.sqlite')\n",
    "\n",
    "TN_hospital_info = pd.read_csv('../data/TN_Hospital_General_Info.csv')\n",
    "\n",
    "# add table to database\n",
    "TN_hospital_info.to_sql('tn_hospital_info', db, if_exists = 'replace', index = False)\n",
    "\n",
    "#create index\n",
    "db.execute('CREATE INDEX facility_id ON tn_hospital_info(facility_id)')\n",
    "\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = sqlite3.connect('../data/hop_teaming_database.sqlite')\n",
    "\n",
    "facility_affiliation = pd.read_csv('../data/Facility_Affiliation.csv', encoding = 'unicode_escape')\n",
    "\n",
    "facility_affiliation.columns = [x.lower() for x in facility_affiliation.columns]\n",
    "\n",
    "# add table to database\n",
    "facility_affiliation.to_sql('facility_affiliation', db, if_exists = 'replace', index = False)\n",
    "\n",
    "# no need to create index, it already has it\n",
    "#db.execute('CREATE INDEX npi ON facility_affiliation(npi)')\n",
    "\n",
    "db.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8ae6d9166a6324ec8fca68373a3fb6f0a0d010f541edaf8017d36667030d4460"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
